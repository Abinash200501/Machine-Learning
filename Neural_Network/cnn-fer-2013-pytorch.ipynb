{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport os\nimport pandas as pd\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:22.731178Z","iopub.execute_input":"2025-06-04T09:34:22.731455Z","iopub.status.idle":"2025-06-04T09:34:31.275697Z","shell.execute_reply.started":"2025-06-04T09:34:22.731433Z","shell.execute_reply":"2025-06-04T09:34:31.275076Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"root_path = r'/kaggle/input/fer2013'\nprint(os.listdir(root_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:31.276989Z","iopub.execute_input":"2025-06-04T09:34:31.277391Z","iopub.status.idle":"2025-06-04T09:34:31.288283Z","shell.execute_reply.started":"2025-06-04T09:34:31.277372Z","shell.execute_reply":"2025-06-04T09:34:31.287704Z"}},"outputs":[{"name":"stdout","text":"['test', 'train']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nclass facial(Dataset):\n    def __init__(self, root_path, transform = None):\n        self.train_folder = []\n        self.test_folder = []\n        self.data = []\n        self.transform = transform\n        for folder in (os.listdir(root_path)):\n            sub_folder = os.path.join(root_path, folder)\n            if \"test\" in sub_folder:\n                self.test_folder.append(sub_folder)\n            else:\n                self.train_folder.append(sub_folder)\n\n        print(\"Train folder:  \", self.train_folder)\n        \n        classes = []\n\n        for train_folder in self.train_folder:\n            for class_folder in (os.listdir(train_folder)):\n                # this will append the name of the subfolders in string format\n                classes.append(class_folder)\n\n        # string format in list class.\n        classes = sorted(classes)\n        print(classes)\n\n        # Give each class a number.\n        class_index = {}\n        for i in range(len(classes)):\n            class_index[classes[i]] = i\n        print(class_index)\n       \n        # now we want to insert the images to that particular class.\n        for train_folder in self.train_folder:\n            # sort the folder before inserting into the class\n            for class_folder in sorted(os.listdir(train_folder)):\n                image_folder = os.path.join(train_folder, class_folder)\n                labels = class_index[class_folder]\n                for img in (os.listdir(image_folder)):\n                    img_path = os.path.join(image_folder, img)\n                    self.data.append((img_path, labels))\n     \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        # here self.data is already a tuple\n        img_path, labels = self.data[index]\n        # convert the image to RGB\n        img = Image.open(img_path).convert(\"L\")\n        \n        if self.transform:\n            img = self.transform(img)\n\n        return img, labels\n\ndataset = facial(root_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:31.289188Z","iopub.execute_input":"2025-06-04T09:34:31.289440Z","iopub.status.idle":"2025-06-04T09:34:32.124745Z","shell.execute_reply.started":"2025-06-04T09:34:31.289417Z","shell.execute_reply":"2025-06-04T09:34:32.124111Z"}},"outputs":[{"name":"stdout","text":"Train folder:   ['/kaggle/input/fer2013/train']\n['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Now we got the dataset and its ready for loading.\n\nall_images = []\nall_labels = []\nfor images, labels in dataset.data:\n    all_images.append(images)\n    all_labels.append(labels)\nprint(\"All Images : \", len(all_images))\nprint(\"All labels : \", set(all_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T05:37:48.154017Z","iopub.execute_input":"2025-07-27T05:37:48.154267Z","iopub.status.idle":"2025-07-27T05:37:48.157994Z","shell.execute_reply.started":"2025-07-27T05:37:48.154247Z","shell.execute_reply":"2025-07-27T05:37:48.157282Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# we got the train and test image with loaders \n# from this we will get separate train image paths and labels.\n\nfrom PIL import Image\nclass Train(Dataset):\n    def __init__(self, path, labels, transform = None):\n        self.image_path = path\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, index):\n        image = self.image_path[index]\n        labels = self.labels[index]\n        # grayscale image\n        img = Image.open(image).convert(\"L\")\n        if self.transform:\n            img = self.transform(img)\n        return img, labels\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:32.138031Z","iopub.execute_input":"2025-06-04T09:34:32.138295Z","iopub.status.idle":"2025-06-04T09:34:32.153426Z","shell.execute_reply.started":"2025-06-04T09:34:32.138267Z","shell.execute_reply":"2025-06-04T09:34:32.152904Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from collections import Counter\n\ntransform = transforms.Compose([transforms.Resize((48, 48)),transforms.ToTensor(),\n                               transforms.Normalize((0.5,), (0.5,))])\n\ntrain_image, test_image, train_labels, test_labels = train_test_split(all_images, all_labels, test_size = 0.2)\n\ntrain_dataset = Train(train_image, train_labels, transform = transform)\ntest_dataset = Train(test_image, test_labels, transform = transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:32.153999Z","iopub.execute_input":"2025-06-04T09:34:32.154260Z","iopub.status.idle":"2025-06-04T09:34:32.179313Z","shell.execute_reply.started":"2025-06-04T09:34:32.154242Z","shell.execute_reply":"2025-06-04T09:34:32.178538Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"label_counts = Counter(train_labels)\n\n# Check how many samples are allocated to the labels.\nprint(\"Train labels distribution:\", Counter(train_labels))\n\nclass_sample_count = [label_counts[i] for i in range(len(label_counts))]\nprint(\"Class sample count : \", class_sample_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:32.180084Z","iopub.execute_input":"2025-06-04T09:34:32.180344Z","iopub.status.idle":"2025-06-04T09:34:32.189519Z","shell.execute_reply.started":"2025-06-04T09:34:32.180310Z","shell.execute_reply":"2025-06-04T09:34:32.188851Z"}},"outputs":[{"name":"stdout","text":"Train labels distribution: Counter({3: 5828, 4: 3936, 5: 3866, 2: 3301, 0: 3160, 6: 2543, 1: 333})\nClass sample count :  [3160, 333, 3301, 5828, 3936, 3866, 2543]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ---------- WeightedRandomSampler to fix class imbalance ---------------------\n# Label 1 (disgust) is having small examples - this denotes this dataset has class imbalance.\n\n# we are dividing it => 1 / 357 (class_count)so the class 1 has higher weight\nweights = 1. / torch.tensor(class_sample_count, dtype=torch.float)\nprint(\"Weight : \", weights)\n\nsamples_weight = [weights[label] for label in train_labels]\nprint(\"Samples weight : \", samples_weight[:7])\n\nsampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:32.190299Z","iopub.execute_input":"2025-06-04T09:34:32.190569Z","iopub.status.idle":"2025-06-04T09:34:32.287206Z","shell.execute_reply.started":"2025-06-04T09:34:32.190547Z","shell.execute_reply":"2025-06-04T09:34:32.286530Z"}},"outputs":[{"name":"stdout","text":"Weight :  tensor([0.0003, 0.0030, 0.0003, 0.0002, 0.0003, 0.0003, 0.0004])\nSamples weight :  [tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003)]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Not using shuffle here because class 1 samples has to picked with higher probability.\ntrain_dataloader = DataLoader(dataset = train_dataset, sampler = sampler, batch_size = 30)\ntest_loader = DataLoader(dataset = test_dataset, shuffle = False, batch_size = 30)\n\nprint(\"Total batch size of train loader: \", len(train_dataloader))\nprint(\"Total length of test loader : \", len(test_loader))\n\nexamples = iter(train_dataloader)\nsamples, labels = next(examples)\nprint(f\"Sample shape : {samples.shape}, labels shape :  {labels.unique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:32.287951Z","iopub.execute_input":"2025-06-04T09:34:32.288175Z","iopub.status.idle":"2025-06-04T09:34:32.652887Z","shell.execute_reply.started":"2025-06-04T09:34:32.288159Z","shell.execute_reply":"2025-06-04T09:34:32.652268Z"}},"outputs":[{"name":"stdout","text":"Total batch size of train loader:  766\nTotal length of test loader :  192\nSample shape : torch.Size([30, 1, 48, 48]), labels shape :  tensor([0, 1, 2, 3, 4, 5, 6])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Define the neural network\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 5)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(32, 64, 5)\n        self.pool = nn.MaxPool2d(2,2)\n        self.fc1 = nn.Linear(64*9*9, 120)\n        self.fc2 = nn.Linear(120, 64)\n        self.fc3 = nn.Linear(64, 7)\n\n    def forward(self, x):\n        out_conv1 = self.relu(self.conv1(x))\n        out_pool = self.relu(self.pool(out_conv1))\n        out_conv2 = self.relu(self.conv2(out_pool))\n        out_pool2 = self.relu(self.pool(out_conv2))\n\n        # flatten the image\n        output = out_pool2.view(-1, 64*9*9)\n\n        out_fc1 = self.relu(self.fc1(output))\n        out_fc2 = self.relu(self.fc2(out_fc1))\n        out_fc3 = self.fc3(out_fc2)\n\n        return out_fc3\n\nmodel = NeuralNetwork()\n\nlearning_rate = 0.001\n\n# loss and optimizer\nloss = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T09:34:32.654783Z","iopub.execute_input":"2025-06-04T09:34:32.654994Z","iopub.status.idle":"2025-06-04T09:34:32.670287Z","shell.execute_reply.started":"2025-06-04T09:34:32.654978Z","shell.execute_reply":"2025-06-04T09:34:32.669745Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"total_steps = len(train_dataloader)\ntotal_epoch = 5\nepoch_loss = 0\nfor epoch in range(total_epoch):\n    for i, (images, labels) in enumerate (train_dataloader):\n        output = model(images)\n        criterion = loss(output, labels)\n\n        optimizer.zero_grad()\n        criterion.backward()\n        optimizer.step()\n\n        batch_loss = criterion.item()\n        \n        epoch_loss += batch_loss\n\n        if (i + 1) % 200 == 0:\n            print(f\"Epoch {epoch+1}, Step {i+1}/{total_steps}, Batch Loss = {batch_loss:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T10:09:25.373770Z","iopub.execute_input":"2025-06-04T10:09:25.374046Z","iopub.status.idle":"2025-06-04T10:14:28.331252Z","shell.execute_reply.started":"2025-06-04T10:09:25.374025Z","shell.execute_reply":"2025-06-04T10:14:28.330642Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Step 200/766, Batch Loss = 0.15263\nEpoch 1, Step 400/766, Batch Loss = 0.23042\nEpoch 1, Step 600/766, Batch Loss = 0.17309\nEpoch 2, Step 200/766, Batch Loss = 0.13871\nEpoch 2, Step 400/766, Batch Loss = 0.12783\nEpoch 2, Step 600/766, Batch Loss = 0.30829\nEpoch 3, Step 200/766, Batch Loss = 0.16196\nEpoch 3, Step 400/766, Batch Loss = 0.09367\nEpoch 3, Step 600/766, Batch Loss = 0.24208\nEpoch 4, Step 200/766, Batch Loss = 0.14752\nEpoch 4, Step 400/766, Batch Loss = 0.20722\nEpoch 4, Step 600/766, Batch Loss = 0.33512\nEpoch 5, Step 200/766, Batch Loss = 0.29840\nEpoch 5, Step 400/766, Batch Loss = 0.15262\nEpoch 5, Step 600/766, Batch Loss = 0.13661\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# loss is fluctuating, so we will find the test accuracy\n\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for image, labels in test_loader :\n        output = model(image)\n        _, predictions = torch.max(output, 1)\n        correct += (predictions == labels).sum().item()\n        total += labels.size(0)\n\n    val_accuracy = 100 * correct / total\n    print(f\"Validation accuracy after epoch : {val_accuracy}\")\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}