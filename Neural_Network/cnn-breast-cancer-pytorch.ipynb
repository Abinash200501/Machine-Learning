{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10564,"sourceType":"datasetVersion","datasetId":7415}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:10:25.049592Z","iopub.execute_input":"2025-06-03T09:10:25.050052Z","iopub.status.idle":"2025-06-03T09:10:25.053741Z","shell.execute_reply.started":"2025-06-03T09:10:25.050027Z","shell.execute_reply":"2025-06-03T09:10:25.053084Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\n\n# get the dataset and preprocessing it\npath = r'/kaggle/input/breast-histopathology-images'\nclass Histopathology(Dataset):\n    def __init__(self, root_path, transform = None):\n        self.transform = transform \n        self.image_path = []\n        self.labels = []\n\n        for folders in (os.listdir(path)):\n            sub_folder = os.path.join(root_path, folders)\n\n            for internal in (os.listdir(sub_folder)):\n                internal_folders = os.path.join(sub_folder, internal)\n                # self.image_path.append(internal_folders)\n                for class_folders in (os.listdir(internal_folders)):\n                    class_folder = os.path.join(internal_folders, class_folders)\n                    if class_folder.endswith('png' or 'jpg' or 'jpeg'):\n                        self.image_path.append(class_folder)\n\n                        # take the labels from the images.\n                        if \"class1\" in class_folder:\n                            label = 1\n                        else:\n                            label = 0\n                        self.labels.append(label)\n    \n\n        print(\"Length : \", len(self.image_path))\n        print(\"Labels : \", len(self.labels))\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, index):\n        image_path = self.image_path[index]\n        image = Image.open(image_path).convert(\"RGB\")\n        labels = self.labels[index]\n       \n        if self.transform:\n            image = self.transform(image)\n        return image, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:11:14.346486Z","iopub.execute_input":"2025-06-03T09:11:14.346796Z","iopub.status.idle":"2025-06-03T09:11:14.353452Z","shell.execute_reply.started":"2025-06-03T09:11:14.346772Z","shell.execute_reply":"2025-06-03T09:11:14.352829Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# split the dataset into train and test\n# all_images, all_labels =  Histopathology(path, transform = transform) - won't work\n# But Histopathology(...) returns a Dataset object, not two variables (all_images, all_labels).\n\n# calling the class and it will automatically call only the _init_ constructor not the len and getitem\ndataset =  Histopathology(path)\nall_images = dataset.image_path\nall_labels = dataset.labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T09:11:19.575016Z","iopub.execute_input":"2025-06-03T09:11:19.575640Z","iopub.status.idle":"2025-06-03T09:11:20.737889Z","shell.execute_reply.started":"2025-06-03T09:11:19.575617Z","shell.execute_reply":"2025-06-03T09:11:20.737133Z"}},"outputs":[{"name":"stdout","text":"Length :  277524\nLabels :  277524\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"class Histopathology_dataset(Dataset):\n    def __init__(self, images, labels , transform = None):\n        self.transform = transform \n        self.image_path = images\n        self.labels = labels\n\n        # This is the check of mapping the image to the respective label\n        if \"class1\" in self.image_path:\n            labels = 1\n        else:\n            labels = 0\n            \n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, index):\n        image_path = self.image_path[index]\n        image = Image.open(image_path).convert(\"RGB\")\n        labels = self.labels[index]\n       \n        if self.transform:\n            image = self.transform(image)\n        return image, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T08:32:31.190906Z","iopub.execute_input":"2025-06-03T08:32:31.191753Z","iopub.status.idle":"2025-06-03T08:32:31.197149Z","shell.execute_reply.started":"2025-06-03T08:32:31.191691Z","shell.execute_reply":"2025-06-03T08:32:31.196469Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# tranform the images and prepare the dataset\ntransform = transforms.Compose([transforms.Resize((50,50)), transforms.ToTensor()])\n\ntrain_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size = 0.3)\nprint(\"Train images : \", len(train_images))\nprint(\"Train labels : \", len(train_labels))\n\nprint(f\"Test images : {len(test_images)}, Test_labels : {len(test_labels)}\")\n\ntrain_dataset = Histopathology_dataset(train_images, train_labels, transform = transform)\ntest_dataset = Histopathology_dataset(test_images, test_labels, transform = transform)\n\n\n# load the data will call len and getitem and retrieve the data\ntrain_dataloader= DataLoader(dataset=train_dataset, shuffle = True, batch_size = 32)\ntest_dataloader= DataLoader(dataset=test_dataset, shuffle = False, batch_size = 32)\n\nbatch = iter(train_dataloader)\nsamples, labels = next(batch)\nprint(f\"Samples shape : {samples.shape}, labels shape : {labels.shape}\")\n\nbatch1 = iter(test_dataloader)\nsamples1, labels1 = next(batch)\nprint(f\"Samples shape : {samples1.shape}, labels shape : {labels1.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T08:44:45.233702Z","iopub.execute_input":"2025-06-03T08:44:45.234390Z","iopub.status.idle":"2025-06-03T08:44:46.079372Z","shell.execute_reply.started":"2025-06-03T08:44:45.234368Z","shell.execute_reply":"2025-06-03T08:44:46.078762Z"}},"outputs":[{"name":"stdout","text":"Train images :  194266\nTrain labels :  194266\nTest images : 83258, Test_labels : 83258\nSamples shape : torch.Size([32, 3, 50, 50]), labels shape : torch.Size([32])\nSamples shape : torch.Size([32, 3, 50, 50]), labels shape : torch.Size([32])\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"class ConvoNetwork(nn.Module):\n    def __init__(self):\n        super(ConvoNetwork, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2,2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.relu = nn.ReLU()\n        self.fc1 = nn.Linear(16*9*9, 100)\n        self.fc2 = nn.Linear(100, 64)\n        self.fc3 = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x1 = self.relu(self.conv1(x))\n        x1 = self.pool(x1)\n        x2 = self.relu(self.conv2(x1))\n        x2 = self.pool(x2)\n\n        # flatten the layer\n        x2 = x2.view(-1, 16*9*9)\n\n        # Pass to the fully connected layer\n        output = self.relu(self.fc1(x2))\n        output = self.relu(self.fc2(output))\n        output = self.relu(self.fc3(output))\n        # Give the sigmoid layer\n        output = torch.sigmoid(output)\n\n        return output\n\nmodel = ConvoNetwork()\n# Loss as BinaryCorssEntropy\nloss = nn.BCELoss()\nlearning_rate = 0.001\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T08:45:19.218572Z","iopub.execute_input":"2025-06-03T08:45:19.219149Z","iopub.status.idle":"2025-06-03T08:45:19.241068Z","shell.execute_reply.started":"2025-06-03T08:45:19.219128Z","shell.execute_reply":"2025-06-03T08:45:19.240523Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"total_steps = len(train_dataloader)\nprint(total_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T08:45:22.711044Z","iopub.execute_input":"2025-06-03T08:45:22.711620Z","iopub.status.idle":"2025-06-03T08:45:22.715255Z","shell.execute_reply.started":"2025-06-03T08:45:22.711598Z","shell.execute_reply":"2025-06-03T08:45:22.714662Z"}},"outputs":[{"name":"stdout","text":"6071\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# train your model\ntotal_epoch = 3\nfor epoch in range(total_epoch):\n    for i, (images, labels) in enumerate(train_dataloader):\n        output = model(images)\n        # make the label size as same size of output\n        labels = labels.view(-1, 1).float()\n        criterion = loss(output, labels)\n        optimizer.zero_grad()\n        criterion.backward()\n        optimizer.step()\n\n        if (i+1) % 1000 == 0:\n            print(f\"epoch : {epoch + 1}, steps : {i+1}/ {total_steps}, loss = {criterion.item():.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T08:45:24.907590Z","iopub.execute_input":"2025-06-03T08:45:24.908196Z"}},"outputs":[{"name":"stdout","text":"epoch : 1, steps : 1000/ 6071, loss = 0.69315\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_dataloader:\n        output = model(images)\n        _, predictions = torch.max(output, 1)\n        correct += (predictions == labels).sum().item()\n        total += labels.shape[0]\n\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T08:27:12.025717Z","iopub.execute_input":"2025-06-01T08:27:12.026258Z","iopub.status.idle":"2025-06-01T08:28:12.395864Z","shell.execute_reply.started":"2025-06-01T08:27:12.026233Z","shell.execute_reply":"2025-06-01T08:28:12.395160Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 71.65%\n","output_type":"stream"}],"execution_count":261}]}