{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1336,
   "id": "52677c43-bbcb-4fb1-98b4-943e56adfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8486a3e1-9639-43f0-8a7e-f4da45bacf61",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "id": "651e229a-b16b-46f1-8edf-286232e6cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r'C:\\Users\\abiab\\Downloads\\train.csv.zip')\n",
    "X_test = pd.read_csv(r'C:\\Users\\abiab\\Downloads\\test.csv.zip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cea495a9-b3f2-4249-8560-2430d7d61300",
   "metadata": {},
   "source": [
    "print(\"X train shape : \", X_train.shape)\n",
    "print(\"X test shape : \", X_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce2940f3-29db-4e24-9487-ad2084f6eb7d",
   "metadata": {},
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68fbbcf1-2ff7-40e8-accb-c5c908efe766",
   "metadata": {},
   "source": [
    "X_train['title'].iloc[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc7055bc-5767-42cb-bb66-f5e8925c96ca",
   "metadata": {},
   "source": [
    "X_train['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "id": "925b8c3e-d6dd-4b7f-bec4-3791597b564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train.drop(['id', 'author', 'text'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "id": "a01a3740-773e-4420-a8b1-645b4d44ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "id": "e44ab94f-2298-4d39-ab55-4587415a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "id": "4ecd51df-c352-47d5-8422-7639dc16841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7310232f-ce40-43a6-bd20-ec6cd697998c",
   "metadata": {},
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e40027d0-0f52-48ac-a2bb-b52d04e5b9bc",
   "metadata": {},
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8d20923-9f4a-4836-8b89-87d7170a0551",
   "metadata": {},
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "id": "aa475203-1ad1-4f26-9e2f-881890088b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['length'] = dataframe['title'].apply(len)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00612d11-654f-4445-a255-cc35d9a6ed5c",
   "metadata": {},
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c04afb8-b279-418c-8ff1-c932f34b2677",
   "metadata": {},
   "source": [
    "dataframe.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1efd94ef-1e97-48fa-8b2a-52b74941c9cb",
   "metadata": {},
   "source": [
    "dataframe.hist(column = 'length', by = 'label', bins = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "id": "c869d9cc-9f73-46a1-ae95-c47203931bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "Lemma = WordNetLemmatizer()\n",
    "Messages = dataframe['title']\n",
    "stopwords = stopwords.words('english')\n",
    "def text_preprocess(message):\n",
    "    no_punc = [char for char in message if char not in string.punctuation]\n",
    "    no_punc = ''.join(no_punc)\n",
    "    words = re.sub('[^a-zA-Z]', ' ', no_punc)\n",
    "    return [Lemma.lemmatize(word.lower()) for word in words.split() if word not in stopwords]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56c46677-31f2-443b-98d9-431da306264d",
   "metadata": {},
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "vocab = {'UNK': 0}\n",
    "def build_vocab(message):\n",
    "    tokenized_text = text_preprocess(message)\n",
    "    for token in tokenized_text:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "\n",
    "Messages.progress_apply(build_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "id": "b80ef3a8-3964-4d60-ab94-2e5a5d2c7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(vocab, text):\n",
    "    text = text.split()\n",
    "    numerical_sentence = []\n",
    "    for token in text:\n",
    "        if token in vocab:\n",
    "            numerical_sentence.append(vocab[token])\n",
    "        else:\n",
    "            numerical_sentence.append(vocab['UNK'])\n",
    "    return numerical_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "id": "158dfa4c-a59c-48ec-b632-3ee21d83aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_seq = []\n",
    "for seq in Messages:\n",
    "    training_seq.append(text_to_indices(vocab, seq.lower()))\n",
    "    \n",
    "max_len=max(len(x) for x in training_seq)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fb91033-eb04-4ece-b11d-0efaf8d8fd99",
   "metadata": {},
   "source": [
    "padded_seq = []\n",
    "for seq in training_seq:\n",
    "    padded_seq.append([0] * (max(max_list) - len(seq)) + seq)\n",
    "print(padded_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "id": "179e5d14-ad95-4422-88fe-069e54d6bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, df, vocab, label):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        numerical_question = text_to_indices(self.vocab, self.df.iloc[index].lower())\n",
    "        return torch.tensor(numerical_question), torch.tensor(self.label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "id": "f81fd771-da35-44a1-9ec9-6437a793f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset(Messages, vocab, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "id": "7c5dfb6d-11e8-444c-8038-7a065b108036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fun(batch):\n",
    "    titles, labels = zip(*batch)\n",
    "    titles_padded = pad_sequence(titles, batch_first=True)\n",
    "    labels = torch.stack(labels)\n",
    "    return titles_padded, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "id": "64e627ec-e786-4d9a-847e-bf3e3db006e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, shuffle = True, batch_size = 32, collate_fn = collate_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "23fcc591-fb57-4631-8ed6-347e5462edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, title):\n",
    "        embed = self.embedding(title)     # [batch, seq_len, embed_dim] \n",
    "        hidden, output = self.rnn(embed)    # output : [1, batch, hidden_dim]\n",
    "        final_output = output.squeeze(0)    # [batch, hidden_dim]\n",
    "        output = self.fc(final_output)       # [batch, 1]\n",
    "        return output.squeeze(1)  # [batch]\n",
    "\n",
    "\n",
    "model = RNN(len(vocab), 64, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "8c93e1e1-aee0-4cf2-a61b-06a9615b89df",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "416e1553-26f7-48ff-a892-9d7e93d0a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device='cuda')\n",
    "else:\n",
    "    device = torch.device(device='cpu')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6977041e-d103-4356-8d70-1259e18727e6",
   "metadata": {},
   "source": [
    "# training loop\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (title, label) in enumerate(dataloader):\n",
    "        title = title.to(device)\n",
    "        label = label.to(device)\n",
    "    \n",
    "        output = model(title)\n",
    "        loss = criterion(output, label.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (i % 5000) == 0:\n",
    "            print(f'epoch : {epoch + 1}, step = {i}, loss = {loss.item():.5f}')\n",
    "            print(\"Predictions:\", torch.sigmoid(output[:5]).detach().cpu().numpy())\n",
    "            print(\"Labels     :\", label[:5].cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch + 1} average loss: {avg_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653e493-11eb-40d2-aaab-48041c591ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "id": "3b5cb48f-1fca-492b-af1f-37551ffe82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, title, threshold=0.5):\n",
    "    num_question = text_to_indices(vocab, title)\n",
    "    print(\"Token indices:\", num_question)\n",
    "\n",
    "    if all(tok == vocab['UNK'] for tok in num_question):\n",
    "        print(\"All tokens unknown.\")\n",
    "\n",
    "    question_tensor = torch.tensor(num_question).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(question_tensor)\n",
    "        print(output[:10])\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        print(f\"Predicted probability of Real: {prob:.4f}\")\n",
    "\n",
    "    if prob < threshold:\n",
    "        print(\"Prediction: Fake\")\n",
    "    else:\n",
    "        print(\"Prediction: Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cf083-5018-4985-96e4-932ee47a6e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str = \"Prize win script\".lower()\n",
    "predict(model, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f1719-a76c-4cc8-b68e-042233ee4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "n_samples = 0\n",
    "with torch.no_grad():\n",
    "    for title, labels in dataloader:\n",
    "        title = title.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(title)  \n",
    "        prob = torch.sigmoid(output)\n",
    "        preds = (probs >= 0.5)\n",
    "        \n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (preds == labels).sum().item()\n",
    "    accuracy = 100 * n_correct / n_samples\n",
    "    print(\"accuracy : \", accuracy)\n",
    "print(n_correct)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4945666-7718-4cc8-b0f6-91daabc35856",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, \"You won a prize lottery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "id": "53f48d01-d7f1-4868-bb0f-90435ebcf180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 74.59%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      0.51      0.67     10387\n",
      "        Real       0.66      1.00      0.79      9855\n",
      "\n",
      "    accuracy                           0.75     20242\n",
      "   macro avg       0.83      0.75      0.73     20242\n",
      "weighted avg       0.83      0.75      0.73     20242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for title, labels in dataloader:\n",
    "        title = title.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(title)\n",
    "\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted = (probs > 0.5).float()\n",
    "        predicted = predicted.view_as(labels)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Now use sklearn metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"✅ Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "report = classification_report(all_labels, all_preds, target_names=[\"Fake\", \"Real\"])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
